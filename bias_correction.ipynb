{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from queue import PriorityQueue\n",
    "import ipywidgets as widgets\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import logging"
   ],
   "id": "f040cf7b989a8c87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "# Configure logging to output to PyCharm's console\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def add_node_with_edges(graph, node_name):\n",
    "    \"\"\"\n",
    "    Add a node to the graph and allow the user to input related edges with direction using widgets in Jupyter Notebook.\n",
    "    Displays immediate edge information on addition and logs actions to console.\n",
    "\n",
    "    Parameters:\n",
    "    graph (nx.DiGraph): The directed graph to add the node and edges to.\n",
    "    node_name (str): The name of the node to add.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Add the node to the graph\n",
    "    graph.add_node(node_name)\n",
    "    display(HTML(f\"<b>Notification:</b> Node '{node_name}' has been added to the graph.\"))\n",
    "    logger.info(f\"Node '{node_name}' has been added to the graph.\")\n",
    "\n",
    "    # Define output widget\n",
    "    global node_dropdown, user_text, root_text, direction_dropdown, output\n",
    "    output = widgets.Output()\n",
    "\n",
    "    # Function to handle edge addition\n",
    "    def add_edge(b):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(f\"<b>Notification:</b> Node '{node_name}' has been added to the graph.\"))\n",
    "            logger.info(f\"Add Edge button clicked for node '{node_name}'.\")\n",
    "            \n",
    "            try:\n",
    "                # Get widget values\n",
    "                target_node = node_dropdown.value\n",
    "                user_prob = float(user_text.value)\n",
    "                root_prob = float(root_text.value)\n",
    "                direction = direction_dropdown.value\n",
    "                \n",
    "                # Validate probabilities\n",
    "                if not (0.0 <= user_prob <= 1.0 and 0.0 <= root_prob <= 1.0):\n",
    "                    display(HTML(\"<b>Error:</b> Probabilities must be in the range [0.0, 1.0]. Please try again.\"))\n",
    "                    logger.error(f\"Invalid probabilities: user={user_prob}, root={root_prob}\")\n",
    "                    return\n",
    "                \n",
    "                # Prepare edge information\n",
    "                edge_info = f\"Edge Info: user={user_prob}, root={root_prob}, direction={direction}\"\n",
    "                \n",
    "                # Add edge based on direction\n",
    "                if direction == \"To Target\":\n",
    "                    graph.add_edge(node_name, target_node, user=user_prob, root=root_prob)\n",
    "                    edge_msg = f\"Edge from '{node_name}' to '{target_node}' ({edge_info})\"\n",
    "                elif direction == \"From Target\":\n",
    "                    graph.add_edge(target_node, node_name, user=user_prob, root=root_prob)\n",
    "                    edge_msg = f\"Edge from '{target_node}' to '{node_name}' ({edge_info})\"\n",
    "                else:  # Bidirectional\n",
    "                    graph.add_edge(node_name, target_node, user=user_prob, root=root_prob)\n",
    "                    graph.add_edge(target_node, node_name, user=user_prob, root=root_prob)\n",
    "                    edge_msg = f\"Bidirectional edge between '{node_name}' and '{target_node}' ({edge_info})\"\n",
    "                \n",
    "                # Display and log edge info immediately\n",
    "                display(HTML(f\"<b>Notification:</b> {edge_msg} has been added.\"))\n",
    "                logger.info(f\"{edge_msg} has been added.\")\n",
    "                display_widgets()  # Redisplay widgets for next edge\n",
    "            except ValueError:\n",
    "                display(HTML(\"<b>Error:</b> Invalid input for probabilities. Please enter valid numbers.\"))\n",
    "                logger.error(\"Invalid input for probabilities.\")\n",
    "\n",
    "    # Function to handle stopping\n",
    "    def stop_adding(b):\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(f\"<b>Notification:</b> Finished adding edges for node '{node_name}'.\"))\n",
    "            logger.info(f\"Finished adding edges for node '{node_name}'.\")\n",
    "\n",
    "    # Function to display widgets\n",
    "    def display_widgets():\n",
    "        with output:\n",
    "            clear_output(wait=True)\n",
    "            # Get list of existing nodes\n",
    "            existing_nodes = list(graph.nodes())\n",
    "            if not existing_nodes:\n",
    "                display(HTML(\"<b>Warning:</b> No existing nodes in the graph.\"))\n",
    "                logger.warning(\"No existing nodes in the graph.\")\n",
    "                return\n",
    "            \n",
    "            # Create widgets\n",
    "            global node_dropdown, user_text, root_text, direction_dropdown\n",
    "            node_dropdown = widgets.Dropdown(\n",
    "                options=existing_nodes,\n",
    "                description='Target Node:',\n",
    "                disabled=False\n",
    "            )\n",
    "            user_text = widgets.FloatText(\n",
    "                value=0.0,\n",
    "                description='User Prob:',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "            root_text = widgets.FloatText(\n",
    "                value=0.0,\n",
    "                description='Root Prob:',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "            direction_dropdown = widgets.Dropdown(\n",
    "                options=[\"To Target\", \"From Target\", \"Bidirectional\"],\n",
    "                description='Edge Direction:',\n",
    "                disabled=False\n",
    "            )\n",
    "            add_button = widgets.Button(description=\"Add Edge\")\n",
    "            stop_button = widgets.Button(description=\"Stop\")\n",
    "\n",
    "            # Assign button callbacks with debug logging\n",
    "            def on_add_button_clicked(b):\n",
    "                logger.info(\"Add Edge button event triggered.\")\n",
    "                add_edge(b)\n",
    "            \n",
    "            def on_stop_button_clicked(b):\n",
    "                logger.info(\"Stop button event triggered.\")\n",
    "                stop_adding(b)\n",
    "\n",
    "            add_button.on_click(on_add_button_clicked)\n",
    "            stop_button.on_click(on_stop_button_clicked)\n",
    "\n",
    "            # Display widgets and initial message\n",
    "            display(HTML(f\"<b>Adding edges from/to '{node_name}':</b>\"))\n",
    "            display(node_dropdown, user_text, root_text, direction_dropdown, add_button, stop_button)\n",
    "\n",
    "    # Initial display of widgets\n",
    "    display(output)\n",
    "    display_widgets()"
   ],
   "id": "52b28a02bff3aead"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Original graph setup\n",
    "G_original = nx.DiGraph()\n",
    "edges = [\n",
    "    (\"Attacker\", \"Pad\", {\"user\": 0.6, \"root\": 0.6}),\n",
    "    (\"Attacker\", \"Web Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Attacker\", \"Host 1\", {\"user\": 0.6, \"root\": 0.48}),\n",
    "    (\"Pad\", \"Host 1\", {\"user\": 0.6, \"root\": 0.48}),\n",
    "    (\"Pad\", \"Host 2\", {\"user\": 0.32, \"root\": 0.32}),\n",
    "    (\"Pad\", \"Host 3\", {\"user\": 0.32, \"root\": 0.32}),\n",
    "    (\"Pad\", \"Web Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 1\", \"Pad\", {\"user\": 0.6, \"root\": 0.6}),\n",
    "    (\"Host 1\", \"Web Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 1\", \"Host 2\", {\"user\": 0.32, \"root\": 0.32}),\n",
    "    (\"Host 1\", \"Host 3\", {\"user\": 0.32, \"root\": 0.32}),\n",
    "    (\"Host 2\", \"Host 3\", {\"user\": 0.8, \"root\": 0.8}),\n",
    "    (\"Host 2\", \"File Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 2\", \"Data Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 3\", \"Host 2\", {\"user\": 0.8, \"root\": 0.8}),\n",
    "    (\"Host 3\", \"File Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 3\", \"Data Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Web Server\", \"File Server\", {\"user\": 0.8, \"root\": 0.04}),\n",
    "    (\"Web Server\", \"Data Server\", {\"user\": 0.8, \"root\": 0.04}),\n",
    "    (\"File Server\", \"Data Server\", {\"user\": 0.8, \"root\": 0.04})\n",
    "]\n",
    "G_original.add_edges_from(edges)\n",
    "\n",
    "G_new = G_original.copy()\n",
    "add_node_with_edges(G_new, \"New node\")\n",
    "\n"
   ],
   "id": "a68d64b7f831a32f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(30,25))\n",
    "pos = nx.spring_layout(G_new)\n",
    "\n",
    "nx.draw(G_new, pos, with_labels=True, node_color='orange', edge_color='gray', node_size=2000, font_size=20, font_weight='bold')\n",
    "\n",
    "# Draw edge labels with weights\n",
    "edge_labels = {(u, v): f\"u={d['user']},r={d['root']}\" for u, v, d in G_new.edges(data=True)}\n",
    "nx.draw_networkx_edge_labels(G_new, pos, edge_labels=edge_labels, font_size=20)\n",
    "plt.savefig(\"graph.png\")\n",
    "plt.show()"
   ],
   "id": "52d4e807fcf7f27b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Attacker's greedy attack with randomizer\n",
    "def global_weighted_random_attack(graph, honeypot_nodes, goal):\n",
    "    captured = {\"Attacker\"}\n",
    "    path = [\"Attacker\"]\n",
    "\n",
    "    while True:\n",
    "        # Collect all uncaptured neighbors of compromised nodes\n",
    "        neighbors = []\n",
    "        edge_weights = []\n",
    "        source_nodes = []\n",
    "\n",
    "        for compromised_node in captured:\n",
    "            for neighbor in graph.successors(compromised_node):\n",
    "                if neighbor not in captured:\n",
    "                    edge_data = graph[compromised_node][neighbor]\n",
    "                    weight = edge_data['user'] + edge_data['root']\n",
    "                    neighbors.append(neighbor)\n",
    "                    edge_weights.append(weight)\n",
    "                    source_nodes.append(compromised_node)\n",
    "\n",
    "        if not neighbors:\n",
    "            break\n",
    "\n",
    "        # Normalize weights to probabilities\n",
    "        total_weight = sum(edge_weights)\n",
    "        if total_weight == 0:\n",
    "            break\n",
    "        probabilities = [w / total_weight for w in edge_weights]\n",
    "\n",
    "        # Choose next node randomly based on probabilities\n",
    "        chosen_idx = random.choices(range(len(neighbors)), weights=probabilities, k=1)[0]\n",
    "        chosen_node = neighbors[chosen_idx]\n",
    "        source_node = source_nodes[chosen_idx]\n",
    "\n",
    "        # Add to path and captured\n",
    "        path.append(chosen_node)\n",
    "        captured.add(chosen_node)\n",
    "\n",
    "        # Check stopping conditions\n",
    "        if chosen_node in honeypot_nodes or chosen_node == goal:\n",
    "            break\n",
    "\n",
    "    return path, captured\n",
    "\n",
    "\n",
    "# Attacker's greedy attack with randomizer\n",
    "def greedy_attack_priority_queue(graph, honeypot_nodes, goal):\n",
    "    captured = {\"Attacker\"}\n",
    "    path = [\"Attacker\"]\n",
    "    pq = PriorityQueue()\n",
    "    for neighbor in graph.successors(\"Attacker\"):\n",
    "        weight = max(graph[\"Attacker\"][neighbor]['user'], graph[\"Attacker\"][neighbor]['root'])\n",
    "        randomizer = random.uniform(0, 1)  # Randomizer for tie-breaking\n",
    "        pq.put((-weight, -randomizer, neighbor))  # Sort by -weight, -randomizer, neighbor\n",
    "\n",
    "    while not pq.empty():\n",
    "        neg_weight, neg_randomizer, to_node = pq.get()\n",
    "        weight = -neg_weight\n",
    "        randomizer = -neg_randomizer\n",
    "        if to_node in honeypot_nodes:  # Stop at honeypot node\n",
    "            path.append(to_node)\n",
    "            captured.add(to_node)\n",
    "            break\n",
    "        if to_node not in captured:\n",
    "            captured.add(to_node)\n",
    "            path.append(to_node)\n",
    "            if to_node == goal:\n",
    "                break\n",
    "            for next_node in graph.successors(to_node):\n",
    "                if next_node not in captured:\n",
    "                    next_weight = max(graph[to_node][next_node]['user'], graph[to_node][next_node]['root'])\n",
    "                    next_randomizer = random.uniform(0, 1)  # New randomizer for each edge\n",
    "                    pq.put((-next_weight, -next_randomizer, next_node))\n",
    "    return path, captured\n"
   ],
   "id": "16f53649308b2b7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1. Environment Setup\n",
    "# Environment class\n",
    "class NetworkSecurityEnv:\n",
    "    def __init__(self, G_new, attack_fn, goal=\"Data Server\"):\n",
    "        self.G_new = G_new\n",
    "        self.attack_fn = attack_fn\n",
    "        self.goal = goal\n",
    "        self.nodes = [n for n in G_new.nodes if n not in [\"Attacker\", goal]]\n",
    "        self.num_nodes = len(self.nodes)\n",
    "        self.state = np.zeros(self.num_nodes, dtype=np.float32)\n",
    "        self.node_to_idx = {node: idx for idx, node in enumerate(self.nodes)}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = np.zeros(self.num_nodes, dtype=np.float32)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        honeypot_nodes = []\n",
    "        G = deepcopy(self.G_new)\n",
    "\n",
    "        for i in range(2):\n",
    "            node_idx = np.argmax(action[i])\n",
    "            if action[i, node_idx] == 0:\n",
    "                node_idx = random.randint(0, self.num_nodes - 1)\n",
    "            node = self.nodes[node_idx]\n",
    "            honeypot = f\"Honeypot_{i}\"\n",
    "            honeypot_nodes.append(honeypot)\n",
    "            G.add_node(honeypot)\n",
    "            G.add_edge(node, honeypot, user=0.8, root=0.8)\n",
    "\n",
    "        path, captured = self.attack_fn(G, honeypot_nodes, self.goal)\n",
    "\n",
    "        new_state = np.zeros(self.num_nodes, dtype=np.float32)\n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        if any(h in captured for h in honeypot_nodes):\n",
    "            reward = 1\n",
    "            done = True\n",
    "        elif self.goal in captured:\n",
    "            reward = -1\n",
    "            done = True\n",
    "\n",
    "        for node in captured:\n",
    "            if node in self.node_to_idx:\n",
    "                new_state[self.node_to_idx[node]] = 1\n",
    "\n",
    "        self.state = new_state\n",
    "        return new_state, reward, done, path, captured\n",
    "\n",
    "    def get_action_space_size(self):\n",
    "        return self.num_nodes * (self.num_nodes - 1)"
   ],
   "id": "77ffd0241db0b753"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_space_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, action_space_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ],
   "id": "f4d56d8779afebca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class DQNWithBias(nn.Module):\n",
    "    def __init__(self, base_model, num_old, num_new):\n",
    "        super().__init__()\n",
    "        self.model = base_model\n",
    "        self.num_old = num_old\n",
    "        self.num_new = num_new\n",
    "\n",
    "        self.alpha = nn.Parameter(torch.Tensor([1]))\n",
    "        self.beta = nn.Parameter(torch.Tensor([0]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        q_raw = self.model(x)  \n",
    "\n",
    "        q_old = q_raw[:, :self.num_old]\n",
    "        q_new = q_raw[:, self.num_old:]  # node mới\n",
    "        q_new_corrected = self.alpha * q_new + self.beta\n",
    "\n",
    "        q_corrected = torch.cat([q_old, q_new_corrected], dim=1)\n",
    "        return q_corrected\n"
   ],
   "id": "fc58a5900d883ed9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Helper to convert action index to 2D array\n",
    "def index_to_action(index, num_nodes):\n",
    "    # Map index to two distinct node indices\n",
    "    first = index // (num_nodes - 1)\n",
    "    second = index % (num_nodes - 1)\n",
    "    if second >= first:\n",
    "        second += 1\n",
    "    action = np.zeros((2, num_nodes), dtype=np.float32)\n",
    "    action[0, first] = 1\n",
    "    action[1, second] = 1\n",
    "    return action\n",
    "\n",
    "def action_to_index(action, num_nodes):\n",
    "    # Convert 2D action array to index\n",
    "    first = np.argmax(action[0])\n",
    "    second = np.argmax(action[1])\n",
    "    if second >= first:\n",
    "        second -= 1\n",
    "    return first * (num_nodes - 1) + second "
   ],
   "id": "f9834cfcc4ecf968"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_model(policy_net, target_net, optimizer, episode, path='dqn_model.pth'):\n",
    "    checkpoint = {\n",
    "        'policy_net_state_dict': policy_net.state_dict(),\n",
    "        'target_net_state_dict': target_net.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'episode': episode\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f'Model saved to {path}')"
   ],
   "id": "da69e96b896a9025"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 3. Replay Buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return (\n",
    "            np.array(state),\n",
    "            np.array(action),\n",
    "            np.array(reward),\n",
    "            np.array(next_state),\n",
    "            np.array(done)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ],
   "id": "ba72e3bc947ef38c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "old_num_nodes = 6\n",
    "new_num_nodes = 7\n",
    "old_action_space_size = old_num_nodes * (old_num_nodes - 1)\n",
    "new_action_space_size = new_num_nodes * (new_num_nodes - 1)\n",
    "model_old =  DQN(old_num_nodes, old_action_space_size)\n",
    "model_load = torch.load(\"./Saved_Model/dqn_model.pth\")\n",
    "model_old.load_state_dict(model_load['policy_net_state_dict'])\n",
    "model_new = DQN(new_num_nodes, new_action_space_size)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_new.fc1.weight[:, :old_num_nodes] = model_old.fc1.weight  \n",
    "    model_new.fc1.bias = model_old.fc1.bias\n",
    "\n",
    "    model_new.fc2.load_state_dict(model_old.fc2.state_dict())\n",
    "    model_new.fc3.load_state_dict(model_old.fc3.state_dict())\n",
    "    \n",
    "    model_new.fc4.weight[:old_num_nodes] = model_old.fc4.weight[:old_num_nodes]\n",
    "    model_new.fc4.bias[:old_num_nodes] = model_old.fc4.bias[:old_num_nodes]\n",
    "    \n",
    "    model_new.fc1.weight[:, old_num_nodes:] = torch.nn.init.xavier_uniform_(\n",
    "        model_new.fc1.weight[:, old_num_nodes:])  # Khởi tạo Xavier cho node mới\n",
    "    # Khởi tạo trọng số cho action mới trong fc4\n",
    "    model_new.fc4.weight[old_action_space_size:] = torch.nn.init.xavier_uniform_(\n",
    "        model_new.fc4.weight[old_action_space_size:])\n",
    "    model_new.fc4.bias[old_action_space_size:] = torch.zeros_like(\n",
    "        model_new.fc4.bias[old_action_space_size:])  # Khởi tạo bias bằng 0\n"
   ],
   "id": "e1e98b70662af7b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Khởi tạo môi trường và mô hình\n",
    "env = NetworkSecurityEnv(G_new, global_weighted_random_attack)\n",
    "model = DQNWithBias(model_new, old_num_nodes, new_num_nodes)\n",
    "\n",
    "# # Chỉ fine-tune tầng cuối (fc4)\n",
    "# for name, param in model.model.named_parameters():\n",
    "#     param.requires_grad = ((\"fc4\" or \"fc1\") in name)\n",
    "\n",
    "# # Chỉ tối ưu alpha và beta\n",
    "# optimizer = torch.optim.Adam([model.alpha, model.beta], lr=0.01)\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=5, verbose=True, min_lr=1e-5)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# replay_buffer = ReplayBuffer(capacity=10000)\n",
    "# \n",
    "# \n",
    "# batch_size = 8\n",
    "# target_update_freq = 8\n",
    "# num_episodes = batch_size * 20\n",
    "# losses = []\n",
    "\n",
    "# epsilon = 0.3\n",
    "# successes = 0\n",
    "# for episode in range(1, num_episodes + 1):\n",
    "#     state = env.reset()\n",
    "#     done = False\n",
    "#     total_loss = 0\n",
    "#     episode_steps = 0\n",
    "# \n",
    "#     while not done:\n",
    "#         state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "#         if random.random() < epsilon:\n",
    "#             action_idx = random.randint(0, new_action_space_size - 1)\n",
    "#         else:\n",
    "#             with torch.no_grad():\n",
    "#                 q_values = model(state_tensor)\n",
    "#                 if torch.isnan(q_values).any() or torch.isinf(q_values).any():\n",
    "#                     print(f\"Warning: NaN or Inf in Q-values at episode {episode}\")\n",
    "#                     break\n",
    "#                 action_idx = q_values.argmax().item()\n",
    "#         action = index_to_action(action_idx, new_num_nodes)\n",
    "#         next_state, reward, done, path, captured = env.step(action)\n",
    "#         \n",
    "#         replay_buffer.push(state, action_idx, reward, next_state, done)\n",
    "#         state = next_state\n",
    "#         episode_steps += 1\n",
    "#         \n",
    "#         honeypot_nodes = []\n",
    "#         for i in range(2):\n",
    "#             node_idx = np.argmax(action[i])\n",
    "#             honeypot_nodes.append(env.nodes[node_idx])\n",
    "#         print(\"Episode:\",episode )\n",
    "#         if reward == 1:  # Honeypot bẫy được kẻ tấn công\n",
    "#             print(path)\n",
    "#             print(f\"Success\\nHoneypots: {action}\\nHoneypots connected to: {honeypot_nodes}\\n\")\n",
    "#             successes += 1\n",
    "#         elif reward == -1:  # Kẻ tấn công đạt mục tiêu\n",
    "#             print(path)\n",
    "#             print(f\"Failed\\nHoneypots: {action}\\nHoneypots connected to: {honeypot_nodes}\\n\")\n",
    "#             \n",
    "#         # Train từ buffer\n",
    "#         if len(replay_buffer) >= batch_size:\n",
    "#             states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "#             states_tensor = torch.FloatTensor(states)\n",
    "#             actions_tensor = torch.LongTensor(actions)\n",
    "#             rewards_tensor = torch.FloatTensor(rewards)\n",
    "#             next_states_tensor = torch.FloatTensor(next_states)\n",
    "#             dones_tensor = torch.FloatTensor(dones)\n",
    "# \n",
    "#             if not (actions_tensor >= 0).all() or not (actions_tensor < new_action_space_size).all():\n",
    "#                 print(f\"Invalid actions in batch at episode {episode}\")\n",
    "#                 continue\n",
    "# \n",
    "#             optimizer.zero_grad()\n",
    "#             q_pred = model(states_tensor)\n",
    "# \n",
    "#             if torch.isnan(q_pred).any() or torch.isinf(q_pred).any():\n",
    "#                 print(f\"Warning: NaN or Inf in q_pred at episode {episode}\")\n",
    "#                 continue\n",
    "# \n",
    "#             with torch.no_grad():\n",
    "#                 q_next = model(next_states_tensor)\n",
    "#                 q_next_max = q_next.max(1)[0]\n",
    "#                 q_target = rewards_tensor + (1 - dones_tensor) * 0.99 * q_next_max\n",
    "# \n",
    "#             loss = criterion(q_pred, actions_tensor)\n",
    "#             loss.backward() \n",
    "#             optimizer.step()\n",
    "#             total_loss += loss.item()\n",
    "# \n",
    "#     avg_loss = total_loss / max(episode_steps, 1)\n",
    "#     if episode >= batch_size:\n",
    "#         losses.append(avg_loss)\n",
    "#         scheduler.step(avg_loss)\n",
    "# \n",
    "#     if episode % target_update_freq == 0:\n",
    "#         current_lr = optimizer.param_groups[0]['lr']\n",
    "#         print(f\"Episode {episode}, Avg Loss: {avg_loss:.4f}, Alpha: {model.alpha.item():.4f}, Beta: {model.beta.item():.4f}, LR: {current_lr:.6f}\")\n",
    "# dsp = (successes / num_episodes)*100\n",
    "# print(f\"\\nDefense success probability: {dsp:.2f}%\") "
   ],
   "id": "c1728a7dad276cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(range(batch_size, num_episodes + 1), losses)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.title('Training Loss over Episodes')\n",
    "plt.show()\n"
   ],
   "id": "b738c1d967f57624"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate_model(model, env, num_episodes=1000):\n",
    "    successes = 0\n",
    "    for episode in range(1,num_episodes+1):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        episode_honeypots = []  # Lưu vị trí honeypot trong episode\n",
    "        \n",
    "        while not done:\n",
    "            with torch.no_grad():\n",
    "                state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "                q_values = model(state_tensor)\n",
    "                action_idx = q_values.argmax().item()\n",
    "                action = index_to_action(action_idx, new_num_nodes)\n",
    "            next_state, reward, done, path, captured = env.step(action)\n",
    "            print (path)\n",
    "            print (captured)    \n",
    "            state = next_state\n",
    "            honeypot_nodes = []\n",
    "            for i in range(2):\n",
    "                node_idx = np.argmax(action[i])\n",
    "                honeypot_nodes.append(env.nodes[node_idx])\n",
    "            print(\"Episode:\",episode )\n",
    "            if reward == 1:  # Honeypot bẫy được kẻ tấn công\n",
    "                successes += 1\n",
    "                print(f\"Success\\nHoneypots: {action}\\nHoneypots connected to: {honeypot_nodes}\\n\")\n",
    "                break\n",
    "            elif reward == -1:  # Kẻ tấn công đạt mục tiêu\n",
    "                print(f\"Failed\\nHoneypots: {action}\\nHoneypots connected to: {honeypot_nodes}\\n\")\n",
    "                break\n",
    "        \n",
    "        \n",
    "    dsp = (successes / num_episodes ) * 100\n",
    "    print(f\"\\nDefense success probability: {dsp:.2f}%\")\n",
    "\n",
    "evaluate_model(model, env)"
   ],
   "id": "4f90e8a47336d86f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
