{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import random\n",
    "from queue import PriorityQueue\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T04:05:48.517075800Z",
     "start_time": "2025-05-12T04:19:47.953083Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 2,
   "source": [
    "# Original graph setup\n",
    "G_original = nx.DiGraph()\n",
    "edges = [\n",
    "    (\"Attacker\", \"Pad\", {\"user\": 0.6, \"root\": 0.6}),\n",
    "    (\"Attacker\", \"Web Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Attacker\", \"Host 1\", {\"user\": 0.6, \"root\": 0.48}),\n",
    "    (\"Pad\", \"Host 1\", {\"user\": 0.6, \"root\": 0.48}),\n",
    "    (\"Pad\", \"Host 2\", {\"user\": 0.32, \"root\": 0.32}),\n",
    "    (\"Pad\", \"Host 3\", {\"user\": 0.32, \"root\": 0.32}),\n",
    "    (\"Pad\", \"Web Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 1\", \"Pad\", {\"user\": 0.6, \"root\": 0.6}),\n",
    "    (\"Host 1\", \"Web Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 1\", \"Host 2\", {\"user\": 0.32, \"root\": 0.32}),\n",
    "    (\"Host 1\", \"Host 3\", {\"user\": 0.32, \"root\": 0.32}),\n",
    "    (\"Host 2\", \"Host 3\", {\"user\": 0.8, \"root\": 0.8}),\n",
    "    (\"Host 2\", \"File Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 2\", \"Data Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 3\", \"Host 2\", {\"user\": 0.8, \"root\": 0.8}),\n",
    "    (\"Host 3\", \"File Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Host 3\", \"Data Server\", {\"user\": 0.8, \"root\": 0.6}),\n",
    "    (\"Web Server\", \"File Server\", {\"user\": 0.8, \"root\": 0.04}),\n",
    "    (\"Web Server\", \"Data Server\", {\"user\": 0.8, \"root\": 0.04}),\n",
    "    (\"File Server\", \"Data Server\", {\"user\": 0.8, \"root\": 0.04})\n",
    "]\n",
    "G_original.add_edges_from(edges)\n"
   ],
   "id": "a60ffc5d033479e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T04:05:48.523444900Z",
     "start_time": "2025-05-12T04:19:48.176121Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 3,
   "source": [
    "# Attacker's greedy attack with randomizer\n",
    "def global_weighted_random_attack(graph, honeypot_nodes, goal):\n",
    "    captured = {\"Attacker\"}\n",
    "    path = [\"Attacker\"]\n",
    "\n",
    "    while True:\n",
    "        # Collect all uncaptured neighbors of compromised nodes\n",
    "        neighbors = []\n",
    "        edge_weights = []\n",
    "        source_nodes = []\n",
    "\n",
    "        for compromised_node in captured:\n",
    "            for neighbor in graph.successors(compromised_node):\n",
    "                if neighbor not in captured:\n",
    "                    edge_data = graph[compromised_node][neighbor]\n",
    "                    weight = edge_data['user'] + edge_data['root']\n",
    "                    neighbors.append(neighbor)\n",
    "                    edge_weights.append(weight)\n",
    "                    source_nodes.append(compromised_node)\n",
    "\n",
    "        if not neighbors:\n",
    "            break\n",
    "\n",
    "        # Normalize weights to probabilities\n",
    "        total_weight = sum(edge_weights)\n",
    "        if total_weight == 0:\n",
    "            break\n",
    "        probabilities = [w / total_weight for w in edge_weights]\n",
    "\n",
    "        # Choose next node randomly based on probabilities\n",
    "        chosen_idx = random.choices(range(len(neighbors)), weights=probabilities, k=1)[0]\n",
    "        chosen_node = neighbors[chosen_idx]\n",
    "        source_node = source_nodes[chosen_idx]\n",
    "\n",
    "        # Add to path and captured\n",
    "        path.append(chosen_node)\n",
    "        captured.add(chosen_node)\n",
    "\n",
    "        # Check stopping conditions\n",
    "        if chosen_node in honeypot_nodes or chosen_node == goal:\n",
    "            break\n",
    "\n",
    "    return path, captured\n",
    "\n",
    "# Attacker's greedy attack with randomizer\n",
    "def greedy_attack_priority_queue(graph, honeypot_nodes, goal):\n",
    "    captured = {\"Attacker\"}\n",
    "    path = [\"Attacker\"]\n",
    "    pq = PriorityQueue()\n",
    "    for neighbor in graph.successors(\"Attacker\"):\n",
    "        weight = max(graph[\"Attacker\"][neighbor]['user'], graph[\"Attacker\"][neighbor]['root'])\n",
    "        randomizer = random.uniform(0, 1)  # Randomizer for tie-breaking\n",
    "        pq.put((-weight, -randomizer, neighbor))  # Sort by -weight, -randomizer, neighbor\n",
    "\n",
    "    while not pq.empty():\n",
    "        neg_weight, neg_randomizer, to_node = pq.get()\n",
    "        weight = -neg_weight\n",
    "        randomizer = -neg_randomizer\n",
    "        if to_node in honeypot_nodes:  # Stop at honeypot node\n",
    "            path.append(to_node)\n",
    "            captured.add(to_node)\n",
    "            break\n",
    "        if to_node not in captured:\n",
    "            captured.add(to_node)\n",
    "            path.append(to_node)\n",
    "            if to_node == goal:\n",
    "                break\n",
    "            for next_node in graph.successors(to_node):\n",
    "                if next_node not in captured:\n",
    "                    next_weight = max(graph[to_node][next_node]['user'], graph[to_node][next_node]['root'])\n",
    "                    next_randomizer = random.uniform(0, 1)  # New randomizer for each edge\n",
    "                    pq.put((-next_weight, -next_randomizer, next_node))\n",
    "    return path, captured\n"
   ],
   "id": "9bdc5ea7305d1679"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T04:05:48.544675600Z",
     "start_time": "2025-05-12T04:19:48.229610Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 4,
   "source": [
    "# 1. Environment Setup\n",
    "# Environment class\n",
    "class NetworkSecurityEnv:\n",
    "    def __init__(self, G_original, attack_fn, goal=\"Data Server\"):\n",
    "        self.G_original = G_original\n",
    "        self.attack_fn = attack_fn\n",
    "        self.goal = goal\n",
    "        # Nodes excluding \"Attacker\" and \"Data Server\"\n",
    "        self.nodes = [n for n in G_original.nodes if n not in [\"Attacker\", goal]]\n",
    "        self.num_nodes = len(self.nodes)\n",
    "        self.state = np.zeros(self.num_nodes, dtype=np.float32)  # Initial state: no nodes attacked\n",
    "        self.node_to_idx = {node: idx for idx, node in enumerate(self.nodes)}\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset state to all zeros for a new episode\n",
    "        self.state = np.zeros(self.num_nodes, dtype=np.float32)\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        # Action is a (2, num_nodes) array, each row is a one-hot vector\n",
    "        honeypot_nodes = []\n",
    "        G = deepcopy(self.G_original)\n",
    "\n",
    "        # Process action to place honeypots\n",
    "        for i in range(2):  # Two honeypots\n",
    "            node_idx = np.argmax(action[i])\n",
    "            if action[i, node_idx] == 0:  # Ensure a valid node is selected\n",
    "                node_idx = random.randint(0, self.num_nodes - 1)\n",
    "            node = self.nodes[node_idx]\n",
    "            honeypot = f\"Honeypot_{i}\"\n",
    "            honeypot_nodes.append(honeypot)\n",
    "            # Add honeypot node with edge to selected node\n",
    "            G.add_node(honeypot)\n",
    "            G.add_edge(node, honeypot, user=0.8, root=0.8)\n",
    "\n",
    "        # Simulate attack\n",
    "        path, captured = self.attack_fn(G, honeypot_nodes, self.goal)\n",
    "\n",
    "        # Determine reward and update state\n",
    "        new_state = np.zeros(self.num_nodes, dtype=np.float32)\n",
    "        reward = 0\n",
    "        done = False\n",
    "\n",
    "        if any(h in captured for h in honeypot_nodes):\n",
    "            reward = 1  # Attacker hit a honeypot\n",
    "            done = True\n",
    "        elif self.goal in captured:\n",
    "            reward = -1  # Attacker reached Data Server\n",
    "            done = True\n",
    "\n",
    "        # Update state: mark attacked nodes as 1\n",
    "        for node in captured:\n",
    "            if node in self.node_to_idx:\n",
    "                new_state[self.node_to_idx[node]] = 1\n",
    "\n",
    "        self.state = new_state\n",
    "        return new_state, reward, done\n",
    "\n",
    "    def get_action_space_size(self):\n",
    "        # Number of valid configurations: choose 2 different nodes for 2 honeypots\n",
    "        return self.num_nodes * (self.num_nodes - 1)"
   ],
   "id": "9b142c63394d2708"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T04:05:48.546745400Z",
     "start_time": "2025-05-12T04:19:48.286900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. DQN Model\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_space_size):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, action_space_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Helper to convert action index to 2D array\n",
    "def index_to_action(index, num_nodes):\n",
    "    # Map index to two distinct node indices\n",
    "    first = index // (num_nodes - 1)\n",
    "    second = index % (num_nodes - 1)\n",
    "    if second >= first:\n",
    "        second += 1\n",
    "    action = np.zeros((2, num_nodes), dtype=np.float32)\n",
    "    action[0, first] = 1\n",
    "    action[1, second] = 1\n",
    "    return action\n",
    "\n",
    "def action_to_index(action, num_nodes):\n",
    "    # Convert 2D action array to index\n",
    "    first = np.argmax(action[0])\n",
    "    second = np.argmax(action[1])\n",
    "    if second >= first:\n",
    "        second -= 1\n",
    "    return first * (num_nodes - 1) + second"
   ],
   "id": "142c5c10b61cd2bc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T04:05:48.548572700Z",
     "start_time": "2025-05-12T04:19:48.346804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Replay Buffer\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return (\n",
    "            np.array(state),\n",
    "            np.array(action),\n",
    "            np.array(reward),\n",
    "            np.array(next_state),\n",
    "            np.array(done)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ],
   "id": "6230132557671d22",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T04:05:48.549558600Z",
     "start_time": "2025-05-12T04:19:48.407369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Training Loop\n",
    "def train_dqn(env, num_episodes=1000, batch_size=10, gamma=0.99, epsilon_start=1.0, epsilon_end=0.01, epsilon_decay=0.995):\n",
    "    state_size = env.num_nodes\n",
    "    action_space_size = env.get_action_space_size()\n",
    "\n",
    "    # Initialize DQN and target network\n",
    "    policy_net = DQN(state_size, action_space_size)\n",
    "    target_net = DQN(state_size, action_space_size)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "\n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=0.001)\n",
    "    replay_buffer = ReplayBuffer(capacity=10000)\n",
    "    epsilon = epsilon_start\n",
    "    total_reward = 0\n",
    "    dsp = 0\n",
    "    for episode in range(num_episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            # Epsilon-greedy action selection\n",
    "            if random.random() < epsilon:\n",
    "                action_idx = random.randint(0, action_space_size - 1)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "                    q_values = policy_net(state_tensor)\n",
    "                    action_idx = q_values.argmax().item()\n",
    "\n",
    "            action = index_to_action(action_idx, env.num_nodes)\n",
    "            next_state, reward, done = env.step(action)\n",
    "            action_idx = action_to_index(action, env.num_nodes)\n",
    "\n",
    "            # Store experience\n",
    "            replay_buffer.push(state, action_idx, reward, next_state, done)\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            if reward == 1 :\n",
    "                dsp += 1\n",
    "            # Train if enough experiences\n",
    "            if len(replay_buffer) >= batch_size:\n",
    "                states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "\n",
    "                states = torch.FloatTensor(states)\n",
    "                actions = torch.LongTensor(actions)\n",
    "                rewards = torch.FloatTensor(rewards)\n",
    "                next_states = torch.FloatTensor(next_states)\n",
    "                dones = torch.FloatTensor(dones)\n",
    "\n",
    "                # Compute Q-values\n",
    "                q_values = policy_net(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "                # Compute target Q-values\n",
    "                with torch.no_grad():\n",
    "                    next_q_values = target_net(next_states).max(1)[0]\n",
    "                    targets = rewards + (1 - dones) * gamma * next_q_values\n",
    "\n",
    "                # Compute loss\n",
    "                loss = nn.MSELoss()(q_values, targets)\n",
    "\n",
    "                # Optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Update target network\n",
    "        if episode % 10 == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "        # Decay epsilon\n",
    "        epsilon = max(epsilon_end, epsilon * epsilon_decay)\n",
    "\n",
    "        # Logging\n",
    "        if (episode  % 100 == 0) & (episode > 0):\n",
    "            placement = []\n",
    "            for i in range(2):  # Two honeypots\n",
    "                node_idx = np.argmax(action[i])\n",
    "                node_name = env.nodes[node_idx]\n",
    "                placement.append(f\"Honeypot {i} -> {node_name}\\n\")\n",
    "            print(f\"Episode {episode}, Total Reward: {total_reward}, Epsilon: {epsilon:.3f}, Defense Success Probability: {dsp/100}%\\n\")\n",
    "            print(\"\".join(placement))\n",
    "            total_reward = 0\n",
    "            dsp = 0\n",
    "\n",
    "    return policy_net\n",
    "\n",
    "# Initialize environment and train\n",
    "algo = global_weighted_random_attack\n",
    "# algo = greedy_attack_priority_queue\n",
    "env = NetworkSecurityEnv(G_original, algo)\n",
    "policy_net = train_dqn(env)"
   ],
   "id": "5377d66c524211df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100, Total Reward: -3, Epsilon: 0.603, Defense Success Probability: 0.49%\n",
      "\n",
      "Honeypot 0 -> Host 1\n",
      "Honeypot 1 -> Pad\n",
      "\n",
      "Episode 200, Total Reward: -4, Epsilon: 0.365, Defense Success Probability: 0.48%\n",
      "\n",
      "Honeypot 0 -> Host 1\n",
      "Honeypot 1 -> File Server\n",
      "\n",
      "Episode 300, Total Reward: 24, Epsilon: 0.221, Defense Success Probability: 0.62%\n",
      "\n",
      "Honeypot 0 -> Pad\n",
      "Honeypot 1 -> Web Server\n",
      "\n",
      "Episode 400, Total Reward: 22, Epsilon: 0.134, Defense Success Probability: 0.61%\n",
      "\n",
      "Honeypot 0 -> Pad\n",
      "Honeypot 1 -> Web Server\n",
      "\n",
      "Episode 500, Total Reward: 22, Epsilon: 0.081, Defense Success Probability: 0.61%\n",
      "\n",
      "Honeypot 0 -> Pad\n",
      "Honeypot 1 -> Web Server\n",
      "\n",
      "Episode 600, Total Reward: 32, Epsilon: 0.049, Defense Success Probability: 0.66%\n",
      "\n",
      "Honeypot 0 -> Pad\n",
      "Honeypot 1 -> Web Server\n",
      "\n",
      "Episode 700, Total Reward: 22, Epsilon: 0.030, Defense Success Probability: 0.61%\n",
      "\n",
      "Honeypot 0 -> Pad\n",
      "Honeypot 1 -> Host 3\n",
      "\n",
      "Episode 800, Total Reward: 22, Epsilon: 0.018, Defense Success Probability: 0.61%\n",
      "\n",
      "Honeypot 0 -> Pad\n",
      "Honeypot 1 -> Web Server\n",
      "\n",
      "Episode 900, Total Reward: 34, Epsilon: 0.011, Defense Success Probability: 0.67%\n",
      "\n",
      "Honeypot 0 -> Pad\n",
      "Honeypot 1 -> Web Server\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T04:05:48.551193900Z",
     "start_time": "2025-05-12T04:19:51.879326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Inference\n",
    "def get_honeypot_placement(policy_net, state, num_nodes):\n",
    "    with torch.no_grad():\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        q_values = policy_net(state_tensor)\n",
    "        action_idx = q_values.argmax().item()\n",
    "        action = index_to_action(action_idx, num_nodes)\n",
    "    return action\n",
    "\n",
    "# Example usage\n",
    "state = env.reset()\n",
    "action = get_honeypot_placement(policy_net, state, env.num_nodes)\n",
    "print(\"Honeypot placement:\\n\", action)\n",
    "# Convert action to node names\n",
    "honeypot_nodes = []\n",
    "for i in range(2):\n",
    "    node_idx = np.argmax(action[i])\n",
    "    honeypot_nodes.append(env.nodes[node_idx])\n",
    "print(\"Honeypots connected to:\", honeypot_nodes)"
   ],
   "id": "33399fff2a66d38e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Honeypot placement:\n",
      " [[0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n",
      "Honeypots connected to: ['Web Server', 'Host 1']\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T04:05:48.552362300Z",
     "start_time": "2025-05-12T04:19:51.929281Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "597785563e2df568",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
